{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QFt3hvyXwOuK"
   },
   "source": [
    "# Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mk4ZiHw1SHHH",
    "outputId": "6ea9ffa9-6aac-4ebc-d07f-423418965c4e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Koush\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x21fe4dd5270>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "import random\n",
    "import re\n",
    "import numpy as np\n",
    "from joblib import load\n",
    "\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "PzoBIZ1ESZCO",
    "outputId": "c8b1ce7e-2244-40bb-9c4c-17a09b09560a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d239b70f786c4e5d9f4afd919a3a499c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "272fdbb64d154037b164b1b37626ed03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12412a21205c4decbab013e456095b3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "\n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    text = text.lower() # lowercase text\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text. substitute the matched string in REPLACE_BY_SPACE_RE with space.\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # remove symbols which are in BAD_SYMBOLS_RE from text. substitute the matched string in BAD_SYMBOLS_RE with nothing.\n",
    "    text = text.replace('x', '')\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # remove stopwors from text\n",
    "    return text\n",
    "\n",
    "# Defining an empty function which will simulate online learning\n",
    "# Currently, not doing it because I don't want to ruin my model weights with test\n",
    "\n",
    "def push_for_online_learning(new_data, new_labels):\n",
    "    \"\"\"\n",
    "    CURRENTLY doing nothing!\n",
    "    \"\"\"\n",
    "    # loading the learned model\n",
    "    model = BertForSequenceClassification.from_pretrained(\"bert_pretrained_augment.pt\")\n",
    "\n",
    "    # setting optimizer and scheduler \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = 1e-5)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 1, gamma = 0.1)\n",
    "\n",
    "    # tokenizing the new data\n",
    "    new_encodings = tokenizer(new_data, truncation=True, padding=True)\n",
    "\n",
    "    # label conversion\n",
    "    # TO DO: label encoding is necessary\n",
    "    new_labels = torch.tensor(new_labels)\n",
    "\n",
    "    # torch readable data\n",
    "    new_dataset = torch.utils.data.TensorDataset(new_encodings['input_ids'], new_encodings['attention_mask'], new_labels)\n",
    "    new_loader = torch.utils.data.DataLoader(new_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "    # loading state dictionary from the saved model\n",
    "    # TO-DO: load the latest weight\n",
    "    model.load_state_dict(torch.load('updated_model_weights_N.pt'))\n",
    "\n",
    "    # training the model on new data\n",
    "    num_epochs = 3\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    model.to(device)\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for batch in new_loader:\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            inputs = {'input_ids': batch[0], 'attention_mask': batch[1], 'labels': batch[2]}\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(**inputs)\n",
    "            loss = outputs[0]\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    # saving the updated model weight\n",
    "    torch.save(model.state_dict(), 'updated_model_weights_N-1.pth')\n",
    "\n",
    "    # TO-DO: better handle of saved model weights so that device don't get full\n",
    "    # Idea: Keep only latest version and latest - 1 version\n",
    "\n",
    "def predict_text_label(query):\n",
    "    \"\"\"\n",
    "    getting predicted label\n",
    "    \"\"\"\n",
    "    encoded_query = tokenizer.encode_plus(clean_text(query), add_special_tokens = True, return_tensors = 'pt')\n",
    "    input_ids = encoded_query['input_ids'].to(device)\n",
    "    attention_mask = encoded_query['attention_mask'].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids, attention_mask)\n",
    "\n",
    "    probs = output.logits.softmax(dim=1).detach().cpu().numpy()\n",
    "    label_index = np.argmax(probs)\n",
    "    label_name = le.inverse_transform([label_index])[0]\n",
    "\n",
    "    return label_name\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert_pretrained_augment.pt\")\n",
    "model.to(device)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case = True)\n",
    "le = load('bert_pretrained_augment_le.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 1:\tI think teachers can create some activities for students that they should use their devices to do them.\n",
      "--------------------\n",
      "\t\tText: I think teachers can create some activities for students that they should use their devices to do them.\n",
      "\t\tClass:\tinteractivity\n",
      "--------------------\n",
      "User 2:\tdasdasdas\n",
      "--------------------\n",
      "\t\tText: dasdasdas\n",
      "\t\tClass:\tgeneric\n",
      "--------------------\n",
      "User 1:\tI think teachers can create some activities for students that they should use their devices to do them.\n",
      "--------------------\n",
      "\t\tText: I think teachers can create some activities for students that they should use their devices to do them.\n",
      "\t\tClass:\tinteractivity\n",
      "--------------------\n",
      "User 2:\tfdf\n",
      "--------------------\n",
      "\t\tText: fdf\n",
      "\t\tClass:\tgeneric\n",
      "--------------------\n",
      "User 1:\tDo you both agree with the following statement: Feedback refers to transmis-  implementation 55  sion of information about learner performance. Why?\n",
      "--------------------\n",
      "\t\tText: Do you both agree with the following statement: Feedback refers to transmis-  implementation 55  sion of information about learner performance. Why?\n",
      "\t\tClass:\ttransmission\n",
      "--------------------\n",
      "User 2:\tss\n",
      "--------------------\n",
      "\t\tText: ss\n",
      "\t\tClass:\tgeneric\n",
      "--------------------\n",
      "User 1:\tDo you both agree with the following statement: Feedback refers to transmission of information about learner performance. Why?\n",
      "--------------------\n",
      "\t\tText: Do you both agree with the following statement: Feedback refers to transmission of information about learner performance. Why?\n",
      "\t\tClass:\ttransmission\n",
      "--------------------\n",
      "User 2:\tI think teachers can create some activities for students that they should use their devices to do them.\n",
      "--------------------\n",
      "\t\tText: I think teachers can create some activities for students that they should use their devices to do them.\n",
      "\t\tClass:\tinteractivity\n",
      "--------------------\n",
      "================================================================================\n",
      "\t\tFeedback Section!\n",
      "--------------------------------------------------------------------------------\n",
      "\t\tIt seems like you have switched your conversation topic!\n",
      "--------------------------------------------------------------------------------\n",
      "\t\tWe detected (last user chat as) - \n",
      "\t\tPartners' Text:\tDo you both agree with the following statement: Feedback refers to transmission of information about learner performance. Why?\n",
      "\t\tPartners' Text Class:\ttransmission\n",
      "----------------------------------------------------------------------\n",
      "\t\tYour Text:\tI think teachers can create some activities for students that they should use their devices to do them.\n",
      "\t\tYour Text Class:\tinteractivity\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Storing predicted classes and new inpurts\n",
    "new_inputs = []\n",
    "predicted_classes = []\n",
    "saved_chat = {}\n",
    "\n",
    "valid_switch = False\n",
    "invalid_switch = False\n",
    "invalid_switch_counter = 0\n",
    "\n",
    "while(1):\n",
    "    u1 = input(\"User 1:\\t\")\n",
    "    lu1 = predict_text_label(u1)\n",
    "    print(\"-\" * 20)\n",
    "    print(f\"\\t\\tText: {u1}\\n\\t\\tClass:\\t{lu1}\")\n",
    "    print(\"-\" * 20)\n",
    "    \n",
    "    # Saving data for user 1\n",
    "    if \"u1\" not in saved_chat:\n",
    "        saved_chat[\"u1\"] = []\n",
    "    saved_chat['u1'].append((u1, lu1, \"none\"))\n",
    "    predicted_classes.append(lu1)\n",
    "    \n",
    "    \n",
    "    u2 = input(\"User 2:\\t\")\n",
    "    lu2 = predict_text_label(u2)\n",
    "    print(\"-\" * 20)\n",
    "    print(f\"\\t\\tText: {u2}\\n\\t\\tClass:\\t{lu2}\")\n",
    "    print(\"-\" * 20)\n",
    "    \n",
    "    \n",
    "    # Saving data for user 2\n",
    "    if \"u2\" not in saved_chat:\n",
    "        saved_chat[\"u2\"] = []\n",
    "    saved_chat['u2'].append((u2, lu2, \"none\"))\n",
    "    predicted_classes.append(lu1)\n",
    "    \n",
    "    \n",
    "    # Storing them for online leaning\n",
    "    # We will perform online learning if we give user a wrongful warning \n",
    "    # Saying that - they are getting out of topic!\n",
    "    \n",
    "    # Checking if we have some previous data or not.\n",
    "    # Because, if the topic switch is from generic to some other topic > that is a valid switch\n",
    "    # If, some other topic to generic switch, and it goes for more than two round, then we will warn user!\n",
    "    # At the same time we will take a feedback if they were on the related topic or not! \n",
    "    \n",
    "    # At the starting of conversation\n",
    "    if len(predicted_classes) <= 2:\n",
    "        # If classified doesn't match\n",
    "        if lu1 != lu2:\n",
    "            \n",
    "            # If it is a transition from \"generic\" topic\n",
    "            if lu1 == \"generic\":\n",
    "                valid_switch = True\n",
    "\n",
    "    # They at least had one round of conversation, then - \n",
    "    else:\n",
    "        # Getting the last saved topic from user 2 to user 1\n",
    "        u2_last_class = predicted_classes[-1]\n",
    "        # u2_last_class = ltup[-1]\n",
    "        \n",
    "        # For user 2, last topic class is lu1\n",
    "        u1_last_class = lu1\n",
    "        \n",
    "        # Now checking if in the beginning of round >=2,\n",
    "        # They user 1 switched topic or not!\n",
    "        \n",
    "        # Meaning, user 1 switched topic\n",
    "        if lu1 != u2_last_class:\n",
    "            \n",
    "            # Since user 1 switched topic, let's see if this switch is from generic or not!\n",
    "            # If switched from generic, then it's valied switch.\n",
    "            if u2_last_class == \"generic\":\n",
    "                valid_switch = True\n",
    "                invalid_switch_counter = 0\n",
    "                \n",
    "            # Else, it is a invalid switch of topic\n",
    "            else:\n",
    "                invalid_switch = True\n",
    "                valid_switch = False\n",
    "                invalid_switch_counter += 1\n",
    "                \n",
    "        # If both matches, then a valid topic switch!\n",
    "        else:\n",
    "            valid_switch = True\n",
    "            invalid_switch_counter = 0\n",
    "        \n",
    "        \n",
    "        # If invalid topic switch counter is 1, we get a feedback that,\n",
    "        # If user 1 switched the topic or not\n",
    "        \n",
    "        if invalid_switch_counter >= 1:\n",
    "            print(80 * \"=\")\n",
    "            print(\"\\t\\tFeedback Section!\")\n",
    "            print(80 * \"-\")\n",
    "            print(\"\\t\\tIt seems like you have switched your conversation topic!\")\n",
    "            print(80 * \"-\")\n",
    "            print(\"\\t\\tWe detected (last user chat as) - \")\n",
    "            print(f\"\\t\\tPartners' Text:\\t{ltuple[0]}\")\n",
    "            print(f\"\\t\\tPartners' Text Class:\\t{ltuple[1]}\")\n",
    "            print(70 * \"-\")\n",
    "            print(f\"\\t\\tYour Text:\\t{u1}\")\n",
    "            print(f\"\\t\\tYour Text Class:\\t{lu1}\")\n",
    "            print(70 * \"-\")\n",
    "            u1_input = input(\"\\t\\tHave you switched your topic in the mentioned class? ('yes'/'no')\")\n",
    "            \n",
    "            # If user disagrees then\n",
    "            if u1_input == \"no\":\n",
    "                saved_chat['u1'][-1] = (u1, ltuple[0], \"feedbacked\")\n",
    "            print(80 * \"-\")\n",
    "            print(\"\\t\\tThank you for the feedback!\")\n",
    "            print(80 * \"=\")\n",
    "        \n",
    "        \n",
    "        # Now checking, if at the end of round two if user 2 switched topic or not\n",
    "        if lu2 != u1_last_class:\n",
    "            \n",
    "            # Since user 2 switched topic, let's see if this switch is to generic or not!\n",
    "            # If switched from generic, then it's valied switch.\n",
    "            if lu2 == \"generic\":\n",
    "                valid_switch = True\n",
    "                invalid_switch_counter = 0\n",
    "\n",
    "            # Else, it is an invalid switch!\n",
    "            else:\n",
    "                invalid_switch = True\n",
    "                valid_switch = False\n",
    "                invalid_switch_counter += 1\n",
    "                \n",
    "        # If both matches, then a valid topic switch!\n",
    "        else:\n",
    "            valid_switch = True\n",
    "            invalid_switch_counter = 0\n",
    "\n",
    "        if invalid_switch_counter >= 1:\n",
    "            print(80 * \"=\")\n",
    "            print(\"\\t\\tFeedback Section!\")\n",
    "            print(80 * \"-\")\n",
    "            print(\"\\t\\tIt seems like you have switched your conversation topic!\")\n",
    "            print(80 * \"-\")\n",
    "            print(\"\\t\\tWe detected (last user chat as) - \")\n",
    "            print(f\"\\t\\tPartners' Text:\\t{u1}\")\n",
    "            print(f\"\\t\\tPartners' Text Class:\\t{lu1}\")\n",
    "            print(70 * \"-\")\n",
    "            print(f\"\\t\\tYour Text:\\t{u2}\")\n",
    "            print(f\"\\t\\tYour Text Class:\\t{lu2}\")\n",
    "            print(70 * \"-\")\n",
    "            u1_input = input(\"\\t\\tHave you switched your topic in the mentioned class? ('yes'/'no')\")\n",
    "            \n",
    "            # If user disagrees then\n",
    "            if u1_input == \"no\":\n",
    "                saved_chat['u2'][-1] = (u2, lu1, \"feedbacked\")\n",
    "            print(80 * \"-\")\n",
    "            print(\"\\t\\tThank you for the feedback!\")\n",
    "            print(80 * \"=\")\n",
    "    \n",
    "    # If concurrent topic switch counter get more a certain number, then we can warn the users\n",
    "    # so that they can stick to the main topic.\n",
    "    \n",
    "    # This could be set to 2 (1 or 2, using trial and error)\n",
    "    # Also, not forcing this warning by checking the length of predicted class (can be a fixed number by trial and error)\n",
    "    topic_switch_level = 1\n",
    "    if invalid_switch_counter >= topic_switch_level and len(predicted_classes):\n",
    "        print(80 * \"+\")\n",
    "        print(\"Warning! Please stick to a topic!\")\n",
    "        print(80 * \"+\")\n",
    "        \n",
    "    \n",
    "    # If last 4 classified labels are of generic class, then they should avoid talking\n",
    "    # on general issues and stick to the main issue\n",
    "    \n",
    "    # This last 4 class cloud be fixed by tiral and error\n",
    "    if len(predicted_classes) >= 4:\n",
    "        tolerance_lavel_on_general_topic = 4 \n",
    "        \n",
    "        last_set = set(predicted_classes[-tolerance_lavel_on_general_topic:])\n",
    "        if len(last_set) == 1 and list(last_set)[-1] == \"generic\":\n",
    "            print(80 * \"+\")\n",
    "            print(\"Warning! Avoid conversation on generic topic!\")\n",
    "            print(80 * \"+\")\n",
    "            \n",
    "    ltuple = (u2, lu2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
