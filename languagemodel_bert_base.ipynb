{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Without Augmentation"
      ],
      "metadata": {
        "id": "QFt3hvyXwOuK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "gzZdsudmYfXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
        "import random\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "mk4ZiHw1SHHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seeds for reproducibility\n",
        "random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"base_df.csv\")\n",
        "df['message'] = df[\"message\"].astype(str)\n",
        "\n",
        "# excluding newly added data\n",
        "df = df[df['category'] != -1]\n",
        "df"
      ],
      "metadata": {
        "id": "B37jfVnvYhXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Preprocessing"
      ],
      "metadata": {
        "id": "rtAXEqiyTmp_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "    text: a string\n",
        "\n",
        "    return: cleaned text\n",
        "    \"\"\"\n",
        "    text = text.lower()\n",
        "    text = replace_symbols.sub(' ', text)\n",
        "    text = bad_symbols.sub('', text)\n",
        "    text = ' '.join(word for word in text.split() if word not in stopwords)\n",
        "    return text\n",
        "\n",
        "# replace symbols by space in text\n",
        "replace_symbols = re.compile('[/(){}\\[\\]\\|@,;]')\n",
        "\n",
        "# remove symbols wfrom text\n",
        "bad_symbols = re.compile('[^0-9a-z #+_]')\n",
        "\n",
        "# remove stopwors from text\n",
        "stopwords = set(stopwords.words('english'))\n",
        "\n",
        "# cleaning the data and adding to the same column\n",
        "df['message'] = df['message'].apply(clean_text)\n",
        "df"
      ],
      "metadata": {
        "id": "PzoBIZ1ESZCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BERT training"
      ],
      "metadata": {
        "id": "tCsrSC2qUVU4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# train and validation/test split\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(df[\"message\"], df[\"field\"], test_size = 0.2, random_state = 42)\n",
        "val_texts, test_texts, val_labels, test_labels = train_test_split(val_texts, val_labels, test_size = 0.5, random_state = 42)\n",
        "\n",
        "# label encodings\n",
        "le = LabelEncoder()\n",
        "train_labels = le.fit_transform(train_labels)\n",
        "val_labels = le.transform(val_labels)\n",
        "test_labels = le.transform(test_labels)\n",
        "\n",
        "# loading pretrained tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case = True)"
      ],
      "metadata": {
        "id": "rQ7C6opOk5BH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizing and encoding train and val set\n",
        "train_encodings = tokenizer(train_texts.tolist(), truncation = True, padding = True)\n",
        "val_encodings = tokenizer(val_texts.tolist(), truncation = True, padding = True)\n",
        "test_encodings = tokenizer(test_texts.tolist(), truncation = True, padding = True)\n",
        "\n",
        "# creating dataset class\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # setting labels\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ],
      "metadata": {
        "id": "tqxizpBdlBtj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# getting dataset objects\n",
        "train_dataset = MyDataset(train_encodings, train_labels)\n",
        "val_dataset = MyDataset(val_encodings, val_labels)\n",
        "test_dataset = MyDataset(test_encodings, test_labels)\n",
        "\n",
        "# hyperparameters\n",
        "batch_size = 16\n",
        "num_epochs = 3\n",
        "\n",
        "# loading pretrained model\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels = len(le.classes_))\n",
        "\n",
        "# setting optimizer\n",
        "optimizer = AdamW(model.parameters(), lr = 5e-5)\n",
        "\n",
        "# setting scheduler\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps = len(train_dataset) * num_epochs // batch_size)"
      ],
      "metadata": {
        "id": "vMV3nHvNlGE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define function for computing accuracy\n",
        "def compute_accuracy(preds, labels):\n",
        "    return (preds == labels).mean()\n",
        "\n",
        "# Train model\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "# model to device and setting for training\n",
        "model.to(device)\n",
        "model.train()\n",
        "\n",
        "# loading train data\n",
        "train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)"
      ],
      "metadata": {
        "id": "9yduOx6BlTcp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, val_texts, val_labels, tokenizer, device):\n",
        "    \"\"\"\n",
        "    this function will return validation loss and accuracy on the validation set\n",
        "    \"\"\"\n",
        "    # val dataloader\n",
        "    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "    # evaluating model on the val set\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    val_acc = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # for each batch in validation loader\n",
        "        for batch in val_loader:\n",
        "            # getting embeddings, attentionmask and labels\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            # getting output for the batch\n",
        "            outputs = model(input_ids, attention_mask = attention_mask, labels = labels)\n",
        "\n",
        "            # getting losses and accuracies\n",
        "            val_loss += outputs.loss.item()\n",
        "            val_acc += (outputs.logits.argmax(dim = 1) == labels).sum().item()\n",
        "\n",
        "    val_loss /= len(val_loader)\n",
        "    val_acc /= len(val_dataset)\n",
        "\n",
        "    return val_loss, val_acc"
      ],
      "metadata": {
        "id": "XYXAt6cVqb3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# starting to train\n",
        "model.train()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = 0\n",
        "    train_preds = []\n",
        "    train_labels = []\n",
        "\n",
        "    # getting batches in train data\n",
        "    for batch in train_loader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        # getting output and computing losses\n",
        "        outputs = model(input_ids, attention_mask = attention_mask, labels = labels)\n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        "\n",
        "        # bw pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # trian loss\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        preds = torch.argmax(logits, dim = 1).detach().cpu().numpy().tolist()\n",
        "        train_preds.extend(preds)\n",
        "        train_labels.extend(labels.detach().cpu().numpy().tolist())\n",
        "\n",
        "    # final accuracies on train and val set\n",
        "    train_acc = accuracy_score(train_labels, train_preds)\n",
        "    val_loss, val_acc = evaluate(model, val_texts, val_labels, tokenizer, device)\n",
        "\n",
        "    print(f'Epoch {epoch + 1}, Train Loss: {train_loss / len(train_loader) : .3f}, Train Acc: {train_acc : .3f}, Val Acc: {val_acc : .3f}')\n"
      ],
      "metadata": {
        "id": "lWaQKzbCp5TA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluating on test set\n",
        "model.eval()\n",
        "\n",
        "# getting test loss and accuracy\n",
        "test_loss, test_acc = evaluate(model, test_texts, test_labels, tokenizer, device)\n",
        "print(f\"Test Loss: {test_loss : .4f}, Test Accuracy: {test_acc : .4f}\")"
      ],
      "metadata": {
        "id": "JTzaVKC7ri-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing on Holdout Set"
      ],
      "metadata": {
        "id": "JyyCk5rFXlNn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# testing on a specific query\n",
        "query = \"Hello there! How are you?\"\n",
        "\n",
        "# encoding query\n",
        "encoded_query = tokenizer.encode_plus(query, add_special_tokens = True, return_tensors = 'pt')\n",
        "\n",
        "# switching to device\n",
        "input_ids = encoded_query['input_ids'].to(device)\n",
        "attention_mask = encoded_query['attention_mask'].to(device)\n",
        "\n",
        "# getting model output by a forward pass\n",
        "with torch.no_grad():\n",
        "    output = model(input_ids, attention_mask)\n",
        "\n",
        "# getting probability\n",
        "probs = output.logits.softmax(dim = 1).detach().cpu().numpy()\n",
        "\n",
        "# getting index of label\n",
        "label_index = np.argmax(probs)\n",
        "\n",
        "# getting label\n",
        "label_name = le.inverse_transform([label_index])[0]\n",
        "\n",
        "print(f\"The predicted label for the query '{query}': {label_name}.\")"
      ],
      "metadata": {
        "id": "q8Vw9Tnkumna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model():\n",
        "    \"\"\"\n",
        "    this function will predict anything any message text availabe on df_name given a model\n",
        "\n",
        "    will return a dictionary dictionary with actual label and predicted label\n",
        "    \"\"\"\n",
        "    # initial correct and wrong\n",
        "    correct = 0\n",
        "    wrong = 0\n",
        "    result = {}\n",
        "\n",
        "    for index, row in pd.read_csv(\"new_data.csv\").iterrows():\n",
        "        query = clean_text(row['message'])\n",
        "\n",
        "        # encoding query\n",
        "        encoded_query = tokenizer.encode_plus(query, add_special_tokens = True, return_tensors = 'pt')\n",
        "\n",
        "        # switching to device\n",
        "        input_ids = encoded_query['input_ids'].to(device)\n",
        "        attention_mask = encoded_query['attention_mask'].to(device)\n",
        "\n",
        "        # getting model output by a forward pass\n",
        "        with torch.no_grad():\n",
        "            output = model(input_ids, attention_mask)\n",
        "\n",
        "        # getting probability\n",
        "        probs = output.logits.softmax(dim = 1).detach().cpu().numpy()\n",
        "\n",
        "        # getting index of label\n",
        "        label_index = np.argmax(probs)\n",
        "\n",
        "        # getting label\n",
        "        predict_label = le.inverse_transform([label_index])[0]\n",
        "\n",
        "        result[index] = {\n",
        "            \"actual_label\" : row['category'],\n",
        "            \"predicted_label\" : predict_label\n",
        "        }\n",
        "\n",
        "        if predict_label == row['category']:\n",
        "            correct += 1\n",
        "        else:\n",
        "            wrong += 1\n",
        "\n",
        "    print(f\"Right: {correct}\\tWrong: {wrong}\")\n",
        "\n",
        "    return result\n",
        "\n",
        "test_model()"
      ],
      "metadata": {
        "id": "dCo067wBwIV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# classification reports\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "def report_for_1k(dct):\n",
        "    # getting confusion matrix for the holdout set\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    for value in list(dct.values()):\n",
        "        y_true.append(value[\"actual_label\"])\n",
        "        y_pred.append(value['predicted_label'])\n",
        "\n",
        "    # getting confustion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    print(\"Confusion Matrix:\")\n",
        "    display(pd.DataFrame(cm, columns = le.classes_, index = le.classes_))\n",
        "\n",
        "    # getting classification report\n",
        "    report = classification_report(y_true, y_pred)\n",
        "    print(\"Classification Report:\")\n",
        "    print(report)\n",
        "\n",
        "report_for_1k(test_model())"
      ],
      "metadata": {
        "id": "tiX7sCwib3lT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# saving model to disk\n",
        "# model.save_pretrained(\"bert_pretrained_no_augment.pt\")"
      ],
      "metadata": {
        "id": "z6sxBCRYWci2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading model from disk\n",
        "# model = BertForSequenceClassification.from_pretrained(\"bert_pretrained_no_augment.pt\")"
      ],
      "metadata": {
        "id": "r9jYD3ByWsjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# With Augmentation"
      ],
      "metadata": {
        "id": "ZnxSgHkjW7hy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loading augmented data\n",
        "df = pd.read_csv(\"updated_final_df.csv\")\n",
        "df['message'] = df[\"message\"].astype(str)\n",
        "df"
      ],
      "metadata": {
        "id": "IvPCafXNwIYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# applying text preprocessing\n",
        "df['message'] = df['message'].apply(clean_text)\n",
        "df"
      ],
      "metadata": {
        "id": "wfkbifGpSBjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train/val/test split\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(df[\"message\"], df[\"topic_field\"], test_size = 0.2, random_state = 42)\n",
        "val_texts, test_texts, val_labels, test_labels = train_test_split(val_texts, val_labels, test_size = 0.5, random_state = 42)\n",
        "\n",
        "# encoding labels\n",
        "le = LabelEncoder()\n",
        "train_labels = le.fit_transform(train_labels)\n",
        "val_labels = le.transform(val_labels)\n",
        "test_labels = le.transform(test_labels)\n",
        "\n",
        "# tokenizing and encoding\n",
        "train_encodings = tokenizer(train_texts.tolist(), truncation = True, padding = True)\n",
        "val_encodings = tokenizer(val_texts.tolist(), truncation = True, padding = True)\n",
        "test_encodings = tokenizer(test_texts.tolist(), truncation = True, padding = True)\n",
        "\n",
        "# creating readable dataset\n",
        "train_dataset = MyDataset(train_encodings, train_labels)\n",
        "val_dataset = MyDataset(val_encodings, val_labels)\n",
        "test_dataset = MyDataset(test_encodings, test_labels)"
      ],
      "metadata": {
        "id": "Fg3mP_f0wPzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model, optimizer, and scheduler initialization\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels = len(le.classes_))\n",
        "optimizer = AdamW(model.parameters(), lr = 5e-5)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps = len(train_dataset) * num_epochs // batch_size)\n",
        "\n",
        "# switching to device\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)\n",
        "model.train()"
      ],
      "metadata": {
        "id": "SmKs-RFdwfyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setting up for training\n",
        "train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
        "model.train()\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = 0\n",
        "    train_preds = []\n",
        "    train_labels = []\n",
        "\n",
        "    # getting batches in train data\n",
        "    for batch in train_loader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        # getting output and computing losses\n",
        "        outputs = model(input_ids, attention_mask = attention_mask, labels = labels)\n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        "\n",
        "        # bw pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # trian loss\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        preds = torch.argmax(logits, dim = 1).detach().cpu().numpy().tolist()\n",
        "        train_preds.extend(preds)\n",
        "        train_labels.extend(labels.detach().cpu().numpy().tolist())\n",
        "\n",
        "    # final accuracies on train and val set\n",
        "    train_acc = accuracy_score(train_labels, train_preds)\n",
        "    val_loss, val_acc = evaluate(model, val_texts, val_labels, tokenizer, device)\n",
        "\n",
        "    print(f'Epoch {epoch + 1}, Train Loss: {train_loss / len(train_loader) : .3f}, Train Acc: {train_acc : .3f}, Val Acc: {val_acc : .3f}')"
      ],
      "metadata": {
        "id": "e0RvrQHVxGAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluating on test set\n",
        "model.eval()\n",
        "\n",
        "# getting test loss and accuracy\n",
        "test_loss, test_acc = evaluate(model, test_texts, test_labels, tokenizer, device)\n",
        "print(f\"Test Loss: {test_loss : .4f}, Test Accuracy: {test_acc : .4f}\")"
      ],
      "metadata": {
        "id": "vquYpkUkxxYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# testing on the holdout data\n",
        "test_model()"
      ],
      "metadata": {
        "id": "zS_ZrtU_YT9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# classification report\n",
        "report_for_1k(test_model())"
      ],
      "metadata": {
        "id": "NzL3nWrYbfGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model to disk\n",
        "# model.save_pretrained(\"bert_pretrained_augment.pt\")"
      ],
      "metadata": {
        "id": "-AQTJB7tZGtA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Summary"
      ],
      "metadata": {
        "id": "CD7bAZi_bFey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchsummary\n",
        "\n",
        "# getting number of sample per batch\n",
        "for batch in train_loader:\n",
        "    num_s = len(batch['labels'])\n",
        "    break\n",
        "\n",
        "torchsummary.summary(model, input_size = [(num_s, tokenizer.max_len_single_sentence), (num_s, tokenizer.max_len_single_sentence)])"
      ],
      "metadata": {
        "id": "XuLCor0TbElN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TO-DOs"
      ],
      "metadata": {
        "id": "YaP4BipDbUnd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TO DO\n",
        "# - Confusion Matrix\n",
        "# - Classification Report\n",
        "\n",
        "# - Discord Integration\n",
        "# - Online learning"
      ],
      "metadata": {
        "id": "IpliUNyZXs-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Online Learning (TO-DO)"
      ],
      "metadata": {
        "id": "kpsICPBbZUaB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the learned model\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert_pretrained_augment.pt\")\n",
        "\n",
        "# setting optimizer and scheduler\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 2e-5)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 1, gamma = 0.1)\n",
        "\n",
        "# new data to load\n",
        "new_data = []\n",
        "new_labels = []\n",
        "\n",
        "# tokenizing the new data\n",
        "new_encodings = tokenizer(new_data, truncation=True, padding=True)\n",
        "\n",
        "# label conversion\n",
        "# TO DO: label encoding is necessary\n",
        "new_labels = torch.tensor(new_labels)\n",
        "\n",
        "# torch readable data\n",
        "new_dataset = torch.utils.data.TensorDataset(new_encodings['input_ids'], new_encodings['attention_mask'], new_labels)\n",
        "new_loader = torch.utils.data.DataLoader(new_dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "# loading state dictionary from the saved model\n",
        "# TO-DO: load the latest weight\n",
        "model.load_state_dict(torch.load('updated_model_weights_N.pt'))\n",
        "\n",
        "# training the model on new data\n",
        "num_epochs = 3\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for batch in new_loader:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        inputs = {'input_ids': batch[0], 'attention_mask': batch[1], 'labels': batch[2]}\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(**inputs)\n",
        "        loss = outputs[0]\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    scheduler.step()\n",
        "\n",
        "# saving the updated model weight\n",
        "torch.save(model.state_dict(), 'updated_model_weights_N-1.pth')\n",
        "\n",
        "# TO-DO: better handle of saved model weights so that device don't get full\n",
        "# Idea: Keep only latest version and latest - 1 version"
      ],
      "metadata": {
        "id": "2tKKcvsyZWYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Application (Idea)"
      ],
      "metadata": {
        "id": "dMgfv4ctcUTi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from joblib import load\n",
        "\n",
        "# Defining an empty function which will simulate online learning\n",
        "# Currently, not doing it because I don't want to ruin my model weights with test\n",
        "\n",
        "def push_for_online_learning():\n",
        "    # Currently doing nothing\n",
        "    # TO-DO\n",
        "    pass\n",
        "\n",
        "def predict_text_label(query):\n",
        "    \"\"\"\n",
        "    getting predicted label\n",
        "    \"\"\"\n",
        "    model = BertForSequenceClassification.from_pretrained(\"bert_pretrained_augment.pt\")\n",
        "    model.to(device)\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case = True)\n",
        "\n",
        "    encoded_query = tokenizer.encode_plus(clean_text(query), add_special_tokens = True, return_tensors = 'pt')\n",
        "    input_ids = encoded_query['input_ids'].to(device)\n",
        "    attention_mask = encoded_query['attention_mask'].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(input_ids, attention_mask)\n",
        "\n",
        "    probs = output.logits.softmax(dim=1).detach().cpu().numpy()\n",
        "    label_index = np.argmax(probs)\n",
        "    le = load('bert_pretrained_augment_le.joblib')\n",
        "    label_name = le.inverse_transform([label_index])[0]\n",
        "\n",
        "    return label_name\n",
        "\n",
        "# Storing predicted classes and new inpurts\n",
        "new_inputs = []\n",
        "predicted_classes = []\n",
        "saved_chat = {}\n",
        "\n",
        "valid_switch = False\n",
        "invalid_switch = False\n",
        "invalid_switch_counter = 0\n",
        "\n",
        "while(0):\n",
        "    u1 = input(\"User 1:\\t\")\n",
        "    lu1 = predict_text_label(u1)\n",
        "    print(f\"Text: {u1}\\tClass:\\t{lu1}\")\n",
        "\n",
        "    # Saving data for user 1\n",
        "    if \"u1\" not in saved_chat:\n",
        "        saved_chat[\"u1\"] = []\n",
        "    saved_chat['u1'].append((u1, lu1, \"none\"))\n",
        "    predicted_classes.append(lu1)\n",
        "\n",
        "\n",
        "    u2 = input(\"User 2:\\t\")\n",
        "    lu2 = predict_text_label(u2)\n",
        "    print(f\"Text: {u2}\\tClass:\\t{lu2}\")\n",
        "\n",
        "    # Saving data for user 2\n",
        "    if \"u2\" not in saved_chat:\n",
        "        saved_chat[\"u2\"] = []\n",
        "    saved_chat['u2'].append((u2, lu2, \"none\"))\n",
        "    predicted_classes.append(lu1)\n",
        "\n",
        "\n",
        "    # Storing them for online leaning\n",
        "    # We will perform online learning if we give user a wrongful warning\n",
        "    # Saying that - they are getting out of topic!\n",
        "\n",
        "    # Checking if we have some previous data or not.\n",
        "    # Because, if the topic switch is from generic to some other topic > that is a valid switch\n",
        "    # If, some other topic to generic switch, and it goes for more than two round, then we will warn user!\n",
        "    # At the same time we will take a feedback if they were on the related topic or not!\n",
        "\n",
        "    # At the starting of conversation\n",
        "    if len(predicted_classes) <= 2:\n",
        "        # If classified doesn't match\n",
        "        if lu1 != lu2:\n",
        "\n",
        "            # If it is a transition from \"generic\" topic\n",
        "            if lu1 == \"generic\":\n",
        "                valid_switch = True\n",
        "\n",
        "    # They at least had one round of conversation, then -\n",
        "    else:\n",
        "        # Getting the last saved topic from user 2 to user 1\n",
        "        u2_last_class = predicted_classes[-1]\n",
        "        # u2_last_class = ltup[-1]\n",
        "\n",
        "        # For user 2, last topic class is lu1\n",
        "        u1_last_class = lu1\n",
        "\n",
        "        # Now checking if in the beginning of round >=2,\n",
        "        # They user 1 switched topic or not!\n",
        "\n",
        "        # Meaning, user 1 switched topic\n",
        "        if lu1 != u2_last_class:\n",
        "\n",
        "            # Since user 1 switched topic, let's see if this switch is from generic or not!\n",
        "            # If switched from generic, then it's valied switch.\n",
        "            if u2_last_class == \"generic\":\n",
        "                valid_switch = True\n",
        "                invalid_switch_counter = 0\n",
        "\n",
        "            # Else, it is a invalid switch of topic\n",
        "            else:\n",
        "                invalid_switch = True\n",
        "                valid_switch = False\n",
        "                invalid_switch_counter += 1\n",
        "\n",
        "        # If both matches, then a valid topic switch!\n",
        "        else:\n",
        "            valid_switch = True\n",
        "            invalid_switch_counter = 0\n",
        "\n",
        "\n",
        "        # If invalid topic switch counter is 1, we get a feedback that,\n",
        "        # If user 1 switched the topic or not\n",
        "\n",
        "        if invalid_switch_counter >= 1:\n",
        "            print(80 * \"=\")\n",
        "            print(\"\\t\\tFeedback Section!\")\n",
        "            print(80 * \"-\")\n",
        "            print(\"\\t\\tIt seems like you have switched your conversation topic!\")\n",
        "            print(80 * \"-\")\n",
        "            print(\"\\t\\tWe detected (last users chat as) - \")\n",
        "            print(f\"\\t\\tPartners' Text:\\t{ltuple[0]}\")\n",
        "            print(f\"\\t\\tPartners' Text Class:\\t{ltuple[1]}\")\n",
        "            print(70 * \"-\")\n",
        "            print(f\"\\t\\tYour Text:\\t{u1}\")\n",
        "            print(f\"\\t\\tYour Text Class:\\t{lu1}\")\n",
        "            print(70 * \"-\")\n",
        "            u1_input = input(\"\\t\\tHave you switched your topic in the mentioned class? ('yes'/'no')\")\n",
        "\n",
        "            # If user disagrees then\n",
        "            if u1_input == \"no\":\n",
        "                saved_chat['u1'][-1] = (u1, ltuple[0], \"feedbacked\")\n",
        "            print(80 * \"-\")\n",
        "            print(\"\\t\\tThank you for the feedback!\")\n",
        "            print(80 * \"=\")\n",
        "\n",
        "\n",
        "        # Now checking, if at the end of round two if user 2 switched topic or not\n",
        "        if lu2 != u1_last_class:\n",
        "\n",
        "            # Since user 2 switched topic, let's see if this switch is to generic or not!\n",
        "            # If switched from generic, then it's valied switch.\n",
        "            if lu2 == \"generic\":\n",
        "                valid_switch = True\n",
        "                invalid_switch_counter = 0\n",
        "\n",
        "            # Else, it is an invalid switch!\n",
        "            else:\n",
        "                invalid_switch = True\n",
        "                valid_switch = False\n",
        "                invalid_switch_counter += 1\n",
        "\n",
        "        # If both matches, then a valid topic switch!\n",
        "        else:\n",
        "            valid_switch = True\n",
        "            invalid_switch_counter = 0\n",
        "\n",
        "        if invalid_switch_counter >= 1:\n",
        "            print(80 * \"=\")\n",
        "            print(\"\\t\\tFeedback Section!\")\n",
        "            print(80 * \"-\")\n",
        "            print(\"\\t\\tIt seems like you have switched your conversation topic!\")\n",
        "            print(80 * \"-\")\n",
        "            print(\"\\t\\tWe detected (last users chat as) - \")\n",
        "            print(f\"\\t\\tPartners' Text:\\t{u1}\")\n",
        "            print(f\"\\t\\tPartners' Text Class:\\t{lu1}\")\n",
        "            print(70 * \"-\")\n",
        "            print(f\"\\t\\tYour Text:\\t{u2}\")\n",
        "            print(f\"\\t\\tYour Text Class:\\t{lu2}\")\n",
        "            print(70 * \"-\")\n",
        "            u1_input = input(\"\\t\\tHave you switched your topic in the mentioned class? ('yes'/'no')\")\n",
        "\n",
        "            # If user disagrees then\n",
        "            if u1_input == \"no\":\n",
        "                saved_chat['u2'][-1] = (u2, lu1, \"feedbacked\")\n",
        "            print(80 * \"-\")\n",
        "            print(\"\\t\\tThank you for the feedback!\")\n",
        "            print(80 * \"=\")\n",
        "\n",
        "    # If concurrent topic switch counter get more a certain number, then we can warn the users\n",
        "    # so that they can stick to the main topic.\n",
        "\n",
        "    # This could be set to 2 (1 or 2, using trial and error)\n",
        "    # Also, not forcing this warning by checking the length of predicted class (can be a fixed number by trial and error)\n",
        "    topic_switch_level = 1\n",
        "    if invalid_switch_counter >= topic_switch_level and len(predicted_classes):\n",
        "        print(\"Warning! Please stick to a topic!\")\n",
        "\n",
        "    # If last 4 classified labels are of generic class, then they should avoid talking\n",
        "    # on general issues and stick to the main issue\n",
        "\n",
        "    # This last 4 class cloud be fixed by tiral and error\n",
        "    if len(predicted_classes) >= 4:\n",
        "        tolerance_lavel_on_general_topic = 4\n",
        "\n",
        "        last_set = set(predicted_classes[-tolerance_lavel_on_general_topic:])\n",
        "        if len(last_set) == 1 and list(last_set)[-1] == \"generic\":\n",
        "            print(\"Warning! Avoid conversation on generic topic!\")\n",
        "    ltuple = (u2, lu2)"
      ],
      "metadata": {
        "id": "HjQZtRcJcWT6"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}